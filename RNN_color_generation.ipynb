{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest =  International orange (aerospace): 1.0,0.31,0.0\n",
      "maxlength =  47\n",
      "number of characters =  48\n",
      "characters =  [' ', '$', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "#Prepare input\n",
    "\n",
    "#Load data\n",
    "names = []\n",
    "rval = []\n",
    "gval = []\n",
    "bval = []\n",
    "bad_chars = ['#', '$', '&', \"'\", '*', '\\x80', '\\x99', '\\xa0', '\\xa9', '\\xba', '\\xc3', '\\xe2']\n",
    "bad_char_string = ''.join(bad_chars)\n",
    "maxlen = 45\n",
    "line_len = []\n",
    "with open('./data/colors.csv') as f:\n",
    "    for li in f.readlines():\n",
    "        line_nospecial = li.translate(None, bad_char_string)\n",
    "        if (len(line_nospecial) < maxlen):\n",
    "            line_split = line_nospecial.split(',')\n",
    "            names.append(line_split[0])\n",
    "            rval.append(float(line_split[1]))\n",
    "            gval.append(float(line_split[2]))\n",
    "            bval.append(float(line_split[3]))\n",
    "            line_len.append(len(line_nospecial))\n",
    "\n",
    "#List of names, properly formated with color values at end\n",
    "names_withrgb = []\n",
    "for ii in xrange(0,len(names)):\n",
    "    names_withrgb.append(names[ii] + ': ' + str(rval[ii]) + ',' + str(gval[ii]) + ',' + str(bval[ii]))\n",
    "\n",
    "#Now format input for RNN\n",
    "end_char = '$' #demarcates end of color name\n",
    "fill_char = '*' #fills in characters to get constant length\n",
    "lengths = map(len, names_withrgb)\n",
    "maxlength = np.max(lengths)+1 #since we add in end character\n",
    "print \"longest = \", names_withrgb[np.argmax(lengths)]\n",
    "print \"maxlength = \", maxlength\n",
    "\n",
    "#turn string into a bunch of data points, filled in to have same length\n",
    "def generate_data_points(string, maxlength):\n",
    "    output = []\n",
    "    for ii in xrange(1,len(string)+1):\n",
    "        new_data_point = fill_char*(maxlength-ii) + string[0:ii]\n",
    "        output.append(new_data_point)\n",
    "    return output\n",
    "\n",
    "all_data = []\n",
    "for ii in xrange(0,len(names_withrgb)):\n",
    "    all_data.extend(generate_data_points(names_withrgb[ii].lower() + end_char, maxlength))\n",
    "\n",
    "#identify unique characters\n",
    "chars = sorted(list(set(''.join(all_data))))\n",
    "#Dictionary to convert characters to numbers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "#Dictionary to convert numbers to characters\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "num_unique_chars = len(chars)\n",
    "\n",
    "print \"number of characters = \", len(chars)\n",
    "dataX = []\n",
    "\n",
    "#Prepare training data\n",
    "dataY = []\n",
    "for ii in xrange(0,len(all_data)):\n",
    "    dataX.append([char_to_int[char] for char in (all_data[ii])[:-1]])\n",
    "    dataY.append(char_to_int[(all_data[ii])[-1]])\n",
    "\n",
    "num_samples = len(dataX)\n",
    "X = np.reshape(dataX, (num_samples, maxlength-1, 1))\n",
    "# normalize\n",
    "X = X / float(num_unique_chars)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print \"characters = \", chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model_suffix = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"./weights/weights-improvement-{epoch:02d}-{loss:.4f}-colors\" + model_suffix + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "43245/43245 [==============================] - 90s 2ms/step - loss: 2.5607\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.56074, saving model to ./weights/weights-improvement-01-2.5607-colorsv1.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f254f4886d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=32, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights - one model is provided by default, but can replace with your own trained model\n",
    "filename = \"./weights/weights-improvement-20-1.3710-colorsv1.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed string =  **********************************************\n",
      "new color =  sale: 0.79,0.94,0.69\n"
     ]
    }
   ],
   "source": [
    "#Generate color using trained network\n",
    "\n",
    "import bisect\n",
    "\n",
    "def draw_rand(pdf):\n",
    "    cdf = np.cumsum(pdf)\n",
    "    rand = np.random.rand(1)\n",
    "    rand_index = bisect.bisect(cdf, rand)\n",
    "    return rand_index\n",
    "\n",
    "def generate_new(model):\n",
    "    seed_start = ''\n",
    "    seed_string = (maxlength-len(seed_start)-1)*fill_char + seed_start\n",
    "    print \"seed string = \", seed_string\n",
    "    seed = [char_to_int[value] for value in seed_string]\n",
    "    output = '*'\n",
    "    \n",
    "    #Higher temperature means probabilities are closer to uniformly distributed\n",
    "    temperature = 0.3\n",
    "    prev_vector = np.copy(seed)\n",
    "    while (output[-1] != end_char and len(output) < maxlength*10):\n",
    "        prev_string = ''.join([int_to_char[prev_vector[i]] for i in np.arange(len(prev_vector))])\n",
    "        #print \"prev vector = \", prev_string\n",
    "        x_shape = np.reshape(prev_vector, (1, maxlength-1, 1))\n",
    "        x_norm = x_shape / float(num_unique_chars)\n",
    "        probs = model.predict(x_norm, verbose=0)\n",
    "        #adjust for temperature\n",
    "        probs_temp = np.exp(np.log(probs)/temperature)\n",
    "        probs_temp = probs_temp/np.sum(probs_temp)\n",
    "        \n",
    "        #draw next character from probability distribution\n",
    "        index = draw_rand(probs_temp)\n",
    "        result = int_to_char[index]\n",
    "            \n",
    "        #add to output and shift prev_vector over one character\n",
    "        output += result\n",
    "        prev_vector = np.append(prev_vector[1:],index)\n",
    "        \n",
    "    output_formatted = output.translate(None, end_char+fill_char)\n",
    "    return output_formatted\n",
    "   \n",
    "\n",
    "new_color = generate_new(model)\n",
    "print \"new color = \", new_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display color\n",
    "color_name_string, color_val_string = new_color.split(':')\n",
    "rgb_strings = color_val_string.split(',')\n",
    "rval, gval, bval = float(rgb_strings[0]), float(rgb_strings[1]), float(rgb_strings[2])\n",
    "color_name_print = r'$\\textbf{' + color_name_string[0].upper() + color_name_string[1:] + '}$'\n",
    "display_mat = np.zeros((1,1,3))\n",
    "display_mat[0,0,0] = rval\n",
    "display_mat[0,0,1] = gval\n",
    "display_mat[0,0,2] = bval\n",
    "\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "fig, ax = pl.subplots(1,1)\n",
    "ax.imshow(display_mat)\n",
    "ax.axis('off')\n",
    "ax.text(0.5, 0.5, color_name_print, size = '30', color = 1.-display_mat[0,0,:], horizontalalignment='center',  verticalalignment='center', transform=ax.transAxes)\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
